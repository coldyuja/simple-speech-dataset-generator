{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "Correction for SepReformerSettings sr duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir, _ = os.path.split(os.path.abspath(os.getcwd()))\n",
    "input = os.path.join(os.getcwd(), 'SepReformer/sample_wav/sample_WSJ.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.vg_types import AudioSetting\n",
    "\n",
    "settings: AudioSetting = {\n",
    "    'mono': True,\n",
    "    'n_fft': None,\n",
    "    'sr': 16000,\n",
    "    'use_torch': True,\n",
    "    'window_size': None,\n",
    "    'opt_settings': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_audio import LoadAudioFile, LoadAudioSettings, LoadAudioBackends\n",
    "\n",
    "load_settings: LoadAudioSettings = {\n",
    "    'backend': LoadAudioBackends.TORCH_SOX,\n",
    "    'effects': [],\n",
    "    'channel_first': True\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = load_settings\n",
    "\n",
    "load_audio = LoadAudioFile(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.simple_elements import ClosureElement\n",
    "\n",
    "only_wav = ClosureElement(lambda _, inp: inp[0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.speech_separation.sepreformer import *\n",
    "\n",
    "sep_model_settings: SepReformerSetting = {\n",
    "    'batch_size': 1,\n",
    "    'chunk_max_len': None,\n",
    "    'distributed_gpu': False,\n",
    "    'model': SepReformerModels.SepReformer_Base_WSJ0,\n",
    "    'n_speaker': 2,\n",
    "    'sr': 16000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_overlap import *\n",
    "\n",
    "sep_settings: SeparateOverlappedSettings = {\n",
    "    'model_settings': sep_model_settings,\n",
    "    'model': SeparateOverlappedModels.SepReformer\n",
    "}\n",
    "\n",
    "overlap_settings: ProcessOverlappedAudioSettings = {\n",
    "    'tasks': ProcessOverlappedAudioTasks.SEPARATE_AUDIO,\n",
    "    'separation_settings': sep_settings\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = overlap_settings\n",
    "overlap_elem = ProcessOverlappedAudio(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index-0 LoadAudioFile Pipeline Output: tuple, shape: None\n",
      "Index-1 ClosureElement Pipeline Output: Tensor, shape: torch.Size([1, 147186])\n",
      "Index-2 ProcessOverlappedAudio Pipeline Output: Tensor, shape: torch.Size([1, 2, 1, 147184])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from simple_vg.pipeline import VGPipeline\n",
    "\n",
    "pipeline_elems = [load_audio, only_wav, overlap_elem]\n",
    "pipeline = VGPipeline()\n",
    "pipeline.sequential(pipeline_elems)\n",
    "pipeline.run(input=input, dbg=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_elem.model.dataset.curr_data_idx = 0\n",
    "overlap_elem.model.dataset.curr_data_idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = overlap_elem.model.dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147186])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_decensoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
