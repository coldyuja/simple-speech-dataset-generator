{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "Correction for SepReformerSettings sr duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir, _ = os.path.split(os.path.abspath(os.getcwd()))\n",
    "input = os.path.join(os.getcwd(), 'sample/sample_WSJ.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.vg_types import AudioSetting\n",
    "\n",
    "settings: AudioSetting = {\n",
    "    'mono': True,\n",
    "    'n_fft': None,\n",
    "    'sr': 16000,\n",
    "    'use_torch': True,\n",
    "    'window_size': None,\n",
    "    'opt_settings': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_audio import LoadAudioFile, LoadAudioSettings, LoadAudioBackends\n",
    "\n",
    "load_settings: LoadAudioSettings = {\n",
    "    'backend': LoadAudioBackends.TORCH_SOX,\n",
    "    'effects': [],\n",
    "    'channel_first': True\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = load_settings\n",
    "\n",
    "load_audio = LoadAudioFile(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_audio import NoiseReductionModels, CleaningAudio, CleaningAudioSetting\n",
    "\n",
    "clean_settings: CleaningAudioSetting = {\n",
    "    'reduce_noise_lib': NoiseReductionModels.NOISEREDUCE,\n",
    "    'stationary': False\n",
    "}\n",
    "settings['opt_settings'] = clean_settings\n",
    "clean_audio = CleaningAudio(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.simple_elements import ClosureElement\n",
    "\n",
    "only_wav = ClosureElement(lambda _, inp: inp[0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.speech_separation.sepreformer import *\n",
    "\n",
    "sep_model_settings: SepReformerSetting = {\n",
    "    'batch_size': 1,\n",
    "    'chunk_max_len': None,\n",
    "    'distributed_gpu': False,\n",
    "    'model': SepReformerModels.SepReformer_Base_WSJ0,\n",
    "    'n_speaker': 2,\n",
    "    'sr': 16000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_overlap import *\n",
    "\n",
    "sep_settings: SeparateOverlappedSettings = {\n",
    "    'model_settings': sep_model_settings,\n",
    "    'model': SeparateOverlappedModels.SepReformer\n",
    "}\n",
    "\n",
    "overlap_settings: ProcessOverlappedAudioSettings = {\n",
    "    'tasks': ProcessOverlappedAudioTasks.SEPARATE_AUDIO,\n",
    "    'separation_settings': sep_settings\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = overlap_settings\n",
    "overlap_elem = ProcessOverlappedAudio(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.activity_detection import *\n",
    "\n",
    "vad_p_settings: VADPipelineSetting = {\n",
    "    'vad_model': VADModels.Silero_VAD\n",
    "}\n",
    "\n",
    "vad_settings: VoiceActivityDetectionSetting = {\n",
    "    'pipeline_settings': vad_p_settings,\n",
    "    'tasks': [\n",
    "        VoiceActivityDetectionTasks.ACTIVITY_DETECTION, \n",
    "        VoiceActivityDetectionTasks.SPLIT_BY_ACTIVITY\n",
    "    ]\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = vad_settings\n",
    "\n",
    "vad_elem = VoiceActivityDetection(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor_squeeze = ClosureElement(lambda _, inp: inp.squeeze(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_vg.extract_text as stt\n",
    "from simple_vg.extract_text import ExtractText\n",
    "\n",
    "stt_settings = stt.default_settings()\n",
    "stt_settings['batch_size'] = 2\n",
    "settings['opt_settings'] = stt_settings\n",
    "stt_mod = ExtractText(settings) \n",
    "#Input shape: (..., S) [(x, y, z, w, S) => view(x*y*z*w=B_stt, S)]\n",
    "#Output shape: (B_stt, S) => [[DecodingResult * ceil(S/3000)] * B_stt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.simple_elements import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_audio_paths = [os.path.relpath(os.path.join(os.getcwd(), 'sample/sample_WSJ_output'+str(i)+'.wav')) for i in range(2)]\n",
    "output_text_data_paths = [os.path.relpath(os.path.join(os.getcwd(), 'sample/sample_WSJ_output.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_audio import SaveAudioFiles, SaveAudioSettings\n",
    "from simple_vg.process_text import ToTextDataset, SaveTextFile\n",
    "settings['opt_settings'] = {}\n",
    "settings['n_channels'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidateElement:\tData: (tensor([[-0.0293, -0.0385, -0.0384,  ..., -0.0384, -0.0499, -0.0310]]), 16000)\n",
      "Index-0 Element: LoadAudioFile Output: tuple, shape: None\n",
      "ValidateElement:\tData: tensor([[-0.0293, -0.0385, -0.0384,  ..., -0.0384, -0.0499, -0.0310]])\n",
      "Index-1 Element: ClosureElement Output: Tensor, shape: torch.Size([1, 147186])\n",
      "ValidateElement:\tData: tensor([[[[-0.0945, -0.0954, -0.1090,  ...,  0.1206,  0.0239, -0.0818]],\n",
      "\n",
      "         [[ 0.0218,  0.0415,  0.0522,  ..., -0.0044,  0.0223,  0.0430]]]],\n",
      "       device='cuda:0')\n",
      "Index-2 Element: ProcessOverlappedAudio Output: Tensor, shape: torch.Size([1, 2, 1, 147184])\n",
      "ProcessAudio\tRoot Input: Tensor, shape: torch.Size([1, 2, 1, 147184])\n",
      "ValidateElement:\tData: tensor([[-0.0945, -0.0954, -0.1090,  ...,  0.1206,  0.0239, -0.0818],\n",
      "        [ 0.0218,  0.0415,  0.0522,  ..., -0.0044,  0.0223,  0.0430]],\n",
      "       device='cuda:0')\n",
      "ProcessAudio-0\tIndex-0 Element: ClosureElement Output: Tensor, shape: torch.Size([2, 147184])\n",
      "ValidateElement:\tData: [tensor([-0.0945, -0.0954, -0.1090,  ...,  0.1206,  0.0239, -0.0818],\n",
      "       device='cuda:0'), tensor([ 0.0218,  0.0415,  0.0522,  ..., -0.0044,  0.0223,  0.0430],\n",
      "       device='cuda:0')]\n",
      "ProcessAudio-0\tIndex-1 Element: ClosureElement Output: list, shape: None\n",
      "ValidateElement:\tData: [tensor([-0.0945, -0.0954, -0.1090,  ...,  0.1206,  0.0239, -0.0818]), tensor([ 0.0218,  0.0415,  0.0522,  ..., -0.0044,  0.0223,  0.0430])]\n",
      "ProcessAudio-0\tIndex-2 Element: TensorToDevice Output: list, shape: None\n",
      "ValidateElement:\tData: [[DecodingResult(audio_features=tensor([[ 0.0355,  0.3967, -0.3843,  ..., -0.0748, -0.6152,  0.1903],\n",
      "        [-0.0533, -0.0036, -0.1083,  ...,  0.2578,  0.6367, -0.2600],\n",
      "        [-0.2637, -0.1631, -0.1570,  ...,  0.0554,  0.6353,  0.6406],\n",
      "        ...,\n",
      "        [-0.1323, -0.3555, -0.0701,  ..., -0.1733, -0.0277,  0.0081],\n",
      "        [-0.2712, -0.0267, -0.4785,  ..., -0.3474, -0.2435, -0.3481],\n",
      "        [-0.2588,  0.0520, -0.5093,  ..., -0.6313,  0.0506,  0.2532]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 13346, 575, 38942, 42893, 294, 5162, 3259, 11, 415, 8194, 572, 643, 337, 264, 12380, 26049, 281, 5300, 1179, 6846, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', avg_logprob=-0.03786372787812177, no_speech_prob=1.205765413729576e-12, temperature=0.0, compression_ratio=1.2881355932203389)], [DecodingResult(audio_features=tensor([[ 0.0564,  0.3457, -0.5815,  ..., -0.1309, -0.2769,  0.2291],\n",
      "        [ 0.0233,  0.1053, -0.3052,  ...,  0.2335,  0.5264, -0.3809],\n",
      "        [-0.1610,  0.0201, -0.1559,  ...,  0.1746,  0.4392,  0.4402],\n",
      "        ...,\n",
      "        [-0.1439, -0.5059, -0.2297,  ..., -0.1155,  0.0188, -0.1002],\n",
      "        [-0.2507, -0.2386, -0.7222,  ..., -0.1769, -0.3096, -0.4573],\n",
      "        [-0.2048,  0.2844, -0.6797,  ..., -0.5000, -0.0027,  0.3591]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 6969, 322, 6984, 11, 264, 3150, 486, 312, 797, 13, 50598, 50605, 634, 8194, 572, 643, 337, 264, 3825, 281, 5300, 264, 5397, 5632, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.', avg_logprob=-0.8740453218158922, no_speech_prob=7.565640822160269e-12, temperature=0.0, compression_ratio=1.2660550458715596)]]\n",
      "ProcessAudio-1\tIndex-0 Element: ExtractText Output: list, shape: None\n",
      "ValidateElement:\tData: ['sample/sample_WSJ_output0.wav', 'sample/sample_WSJ_output1.wav']\n",
      "ProcessAudio-2\tIndex-0 Element: InputElement Output: list, shape: None\n",
      "ValidateElement:\tData: [[tensor([-0.0945, -0.0954, -0.1090,  ...,  0.1206,  0.0239, -0.0818]), tensor([ 0.0218,  0.0415,  0.0522,  ..., -0.0044,  0.0223,  0.0430])], [[DecodingResult(audio_features=tensor([[ 0.0355,  0.3967, -0.3843,  ..., -0.0748, -0.6152,  0.1903],\n",
      "        [-0.0533, -0.0036, -0.1083,  ...,  0.2578,  0.6367, -0.2600],\n",
      "        [-0.2637, -0.1631, -0.1570,  ...,  0.0554,  0.6353,  0.6406],\n",
      "        ...,\n",
      "        [-0.1323, -0.3555, -0.0701,  ..., -0.1733, -0.0277,  0.0081],\n",
      "        [-0.2712, -0.0267, -0.4785,  ..., -0.3474, -0.2435, -0.3481],\n",
      "        [-0.2588,  0.0520, -0.5093,  ..., -0.6313,  0.0506,  0.2532]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 13346, 575, 38942, 42893, 294, 5162, 3259, 11, 415, 8194, 572, 643, 337, 264, 12380, 26049, 281, 5300, 1179, 6846, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', avg_logprob=-0.03786372787812177, no_speech_prob=1.205765413729576e-12, temperature=0.0, compression_ratio=1.2881355932203389)], [DecodingResult(audio_features=tensor([[ 0.0564,  0.3457, -0.5815,  ..., -0.1309, -0.2769,  0.2291],\n",
      "        [ 0.0233,  0.1053, -0.3052,  ...,  0.2335,  0.5264, -0.3809],\n",
      "        [-0.1610,  0.0201, -0.1559,  ...,  0.1746,  0.4392,  0.4402],\n",
      "        ...,\n",
      "        [-0.1439, -0.5059, -0.2297,  ..., -0.1155,  0.0188, -0.1002],\n",
      "        [-0.2507, -0.2386, -0.7222,  ..., -0.1769, -0.3096, -0.4573],\n",
      "        [-0.2048,  0.2844, -0.6797,  ..., -0.5000, -0.0027,  0.3591]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 6969, 322, 6984, 11, 264, 3150, 486, 312, 797, 13, 50598, 50605, 634, 8194, 572, 643, 337, 264, 3825, 281, 5300, 264, 5397, 5632, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.', avg_logprob=-0.8740453218158922, no_speech_prob=7.565640822160269e-12, temperature=0.0, compression_ratio=1.2660550458715596)]], ['sample/sample_WSJ_output0.wav', 'sample/sample_WSJ_output1.wav']]\n",
      "Index-3 Element: ParallelElement Output: list, shape: None\n",
      "ProcessOutput\tRoot Input: list, shape: None\n",
      "ValidateElement:\tData: [[tensor([-0.0945, -0.0954, -0.1090,  ...,  0.1206,  0.0239, -0.0818]), tensor([ 0.0218,  0.0415,  0.0522,  ..., -0.0044,  0.0223,  0.0430])], ['sample/sample_WSJ_output0.wav', 'sample/sample_WSJ_output1.wav']]\n",
      "ProcessOutput-0\tIndex-0 Element: MaskElement Output: list, shape: None\n",
      "ValidateElement:\tData: None\n",
      "ProcessOutput-0\tIndex-1 Element: SaveAudioFiles Output: NoneType, shape: None\n",
      "ValidateElement:\tData: [[[DecodingResult(audio_features=tensor([[ 0.0355,  0.3967, -0.3843,  ..., -0.0748, -0.6152,  0.1903],\n",
      "        [-0.0533, -0.0036, -0.1083,  ...,  0.2578,  0.6367, -0.2600],\n",
      "        [-0.2637, -0.1631, -0.1570,  ...,  0.0554,  0.6353,  0.6406],\n",
      "        ...,\n",
      "        [-0.1323, -0.3555, -0.0701,  ..., -0.1733, -0.0277,  0.0081],\n",
      "        [-0.2712, -0.0267, -0.4785,  ..., -0.3474, -0.2435, -0.3481],\n",
      "        [-0.2588,  0.0520, -0.5093,  ..., -0.6313,  0.0506,  0.2532]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 13346, 575, 38942, 42893, 294, 5162, 3259, 11, 415, 8194, 572, 643, 337, 264, 12380, 26049, 281, 5300, 1179, 6846, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', avg_logprob=-0.03786372787812177, no_speech_prob=1.205765413729576e-12, temperature=0.0, compression_ratio=1.2881355932203389)], [DecodingResult(audio_features=tensor([[ 0.0564,  0.3457, -0.5815,  ..., -0.1309, -0.2769,  0.2291],\n",
      "        [ 0.0233,  0.1053, -0.3052,  ...,  0.2335,  0.5264, -0.3809],\n",
      "        [-0.1610,  0.0201, -0.1559,  ...,  0.1746,  0.4392,  0.4402],\n",
      "        ...,\n",
      "        [-0.1439, -0.5059, -0.2297,  ..., -0.1155,  0.0188, -0.1002],\n",
      "        [-0.2507, -0.2386, -0.7222,  ..., -0.1769, -0.3096, -0.4573],\n",
      "        [-0.2048,  0.2844, -0.6797,  ..., -0.5000, -0.0027,  0.3591]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 6969, 322, 6984, 11, 264, 3150, 486, 312, 797, 13, 50598, 50605, 634, 8194, 572, 643, 337, 264, 3825, 281, 5300, 264, 5397, 5632, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.', avg_logprob=-0.8740453218158922, no_speech_prob=7.565640822160269e-12, temperature=0.0, compression_ratio=1.2660550458715596)]], ['sample/sample_WSJ_output0.wav', 'sample/sample_WSJ_output1.wav']]\n",
      "ProcessOutput-1\tIndex-0 Element: MaskElement Output: list, shape: None\n",
      "ValidateElement:\tData: [{'language': 'en', 'text': 'Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', 'file_path': 'sample/sample_WSJ_output0.wav'}, {'language': 'en', 'text': 'Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.', 'file_path': 'sample/sample_WSJ_output1.wav'}]\n",
      "ProcessOutput-1\tIndex-1 Element: ClosureElement Output: list, shape: None\n",
      "ProcessText\tRoot Input: list, shape: None\n",
      "ValidateElement:\tData: ['sample/sample_WSJ_output0.wav|en|Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', 'sample/sample_WSJ_output1.wav|en|Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.']\n",
      "ProcessText-0\tIndex-0 Element: ToTextDataset Output: list, shape: None\n",
      "ValidateElement:\tData: [['sample/sample_WSJ_output0.wav|en|Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', 'sample/sample_WSJ_output1.wav|en|Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.']]\n",
      "ProcessText-0\tIndex-1 Element: ClosureElement Output: list, shape: None\n",
      "ValidateElement:\tData: ['sample/sample_WSJ_output.txt']\n",
      "ProcessText-1\tIndex-0 Element: InputElement Output: list, shape: None\n",
      "ValidateElement:\tData: [[['sample/sample_WSJ_output0.wav|en|Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', 'sample/sample_WSJ_output1.wav|en|Since the U.S. Green on Friday, the board will be again. He sees no need for the security to raise the credit cards to protect the dollar.']], ['sample/sample_WSJ_output.txt']]\n",
      "ProcessOutput-1\tIndex-2 Element: ParallelElement Output: list, shape: None\n",
      "ValidateElement:\tData: None\n",
      "ProcessOutput-1\tIndex-3 Element: SaveTextFile Output: NoneType, shape: None\n",
      "ValidateElement:\tData: [None, None]\n",
      "Index-4 Element: ParallelElement Output: list, shape: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from simple_vg.pipeline import VGPipeline\n",
    "\n",
    "dbg = True\n",
    "def fit_whisper_result_to_elem_input(elem_obj, input):\n",
    "    output_dicts = []\n",
    "    for decode_results, audio_path in zip(*input):\n",
    "        _dict = {}\n",
    "        script: str = ''\n",
    "        for result in decode_results:\n",
    "            _dict['language'] = result.language\n",
    "            script += result.text\n",
    "        _dict['text'] = script.replace('\\n', ' ')\n",
    "        _dict['file_path'] = audio_path\n",
    "        output_dicts.append(_dict)\n",
    "    return output_dicts\n",
    "\n",
    "pipeline_elems = [\n",
    "    load_audio, \n",
    "    only_wav,\n",
    "    # clean_audio, (seems it does not helped for this sample audio.....) \n",
    "    overlap_elem,\n",
    "    ParallelElement(\n",
    "        [\n",
    "            [\n",
    "                audio_tensor_squeeze,\n",
    "                ClosureElement(lambda _, inp: [inp[i] for i in range(len(inp))], None),\n",
    "                TensorToDevice(device='cpu')\n",
    "            ],\n",
    "            [stt_mod],\n",
    "            [InputElement(output_audio_paths)]\n",
    "        ],\n",
    "        dbg=dbg, name='ProcessAudio'\n",
    "    ),\n",
    "    ParallelElement(\n",
    "        [\n",
    "            [\n",
    "                MaskElement([1, 0, 1]), \n",
    "                SaveAudioFiles(settings)\n",
    "            ],\n",
    "            [\n",
    "                MaskElement([0, 1, 1]),\n",
    "                ClosureElement(fit_whisper_result_to_elem_input, None),\n",
    "                ParallelElement(\n",
    "                    [\n",
    "                        [ToTextDataset(['file_path', 'language', 'text'], default=''), ClosureElement(lambda _, inp: [inp], None)],\n",
    "                        [InputElement(output_text_data_paths)]\n",
    "                    ], dbg=dbg, name='ProcessText'\n",
    "                ),\n",
    "                SaveTextFile()\n",
    "            ]\n",
    "        ], dbg=dbg, name='ProcessOutput'\n",
    "    )\n",
    "    ]\n",
    "pipeline = VGPipeline()\n",
    "pipeline.sequential(pipeline_elems)\n",
    "pipeline.run(input=input, dbg=dbg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_audio.ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_decensoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
