{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "Correction for SepReformerSettings sr duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir, _ = os.path.split(os.path.abspath(os.getcwd()))\n",
    "input = os.path.join(os.getcwd(), 'SepReformer/sample_wav/sample_WSJ.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.vg_types import AudioSetting\n",
    "\n",
    "settings: AudioSetting = {\n",
    "    'mono': True,\n",
    "    'n_fft': None,\n",
    "    'sr': 16000,\n",
    "    'use_torch': True,\n",
    "    'window_size': None,\n",
    "    'opt_settings': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_audio import LoadAudioFile, LoadAudioSettings, LoadAudioBackends\n",
    "\n",
    "load_settings: LoadAudioSettings = {\n",
    "    'backend': LoadAudioBackends.TORCH_SOX,\n",
    "    'effects': [],\n",
    "    'channel_first': True\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = load_settings\n",
    "\n",
    "load_audio = LoadAudioFile(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.simple_elements import ClosureElement\n",
    "\n",
    "only_wav = ClosureElement(lambda _, inp: inp[0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.speech_separation.sepreformer import *\n",
    "\n",
    "sep_model_settings: SepReformerSetting = {\n",
    "    'batch_size': 1,\n",
    "    'chunk_max_len': None,\n",
    "    'distributed_gpu': False,\n",
    "    'model': SepReformerModels.SepReformer_Base_WSJ0,\n",
    "    'n_speaker': 2,\n",
    "    'sr': 16000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.process_overlap import *\n",
    "\n",
    "sep_settings: SeparateOverlappedSettings = {\n",
    "    'model_settings': sep_model_settings,\n",
    "    'model': SeparateOverlappedModels.SepReformer\n",
    "}\n",
    "\n",
    "overlap_settings: ProcessOverlappedAudioSettings = {\n",
    "    'tasks': ProcessOverlappedAudioTasks.SEPARATE_AUDIO,\n",
    "    'separation_settings': sep_settings\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = overlap_settings\n",
    "overlap_elem = ProcessOverlappedAudio(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_vg.activity_detection import *\n",
    "\n",
    "vad_p_settings: VADPipelineSetting = {\n",
    "    'vad_model': VADModels.Silero_VAD\n",
    "}\n",
    "\n",
    "vad_settings: VoiceActivityDetectionSetting = {\n",
    "    'pipeline_settings': vad_p_settings,\n",
    "    'tasks': [\n",
    "        VoiceActivityDetectionTasks.ACTIVITY_DETECTION, \n",
    "        VoiceActivityDetectionTasks.SPLIT_BY_ACTIVITY\n",
    "    ]\n",
    "}\n",
    "\n",
    "settings['opt_settings'] = vad_settings\n",
    "\n",
    "vad_elem = VoiceActivityDetection(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_vg.extract_text as stt\n",
    "from simple_vg.extract_text import ExtractText\n",
    "\n",
    "stt_settings = stt.default_settings()\n",
    "stt_settings['batch_size'] = 2\n",
    "settings['opt_settings'] = stt_settings\n",
    "stt_mod = ExtractText(settings) #Input shape: (..., S) [(x, y, z, w, S) => view(x*y*z*w, S)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index-0 LoadAudioFile Pipeline Output: tuple, shape: None\n",
      "Index-1 ClosureElement Pipeline Output: Tensor, shape: torch.Size([1, 147186])\n",
      "Index-2 ProcessOverlappedAudio Pipeline Output: Tensor, shape: torch.Size([1, 2, 1, 147184])\n",
      "Index-3 ExtractText Pipeline Output: list, shape: None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from simple_vg.pipeline import VGPipeline\n",
    "\n",
    "pipeline_elems = [\n",
    "    load_audio, \n",
    "    only_wav, \n",
    "    overlap_elem,\n",
    "    stt_mod]\n",
    "pipeline = VGPipeline()\n",
    "pipeline.sequential(pipeline_elems)\n",
    "pipeline.run(input=input, dbg=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 919], [1, 0, 919]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt_mod.model.dataset.indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[DecodingResult(audio_features=tensor([[ 0.0347,  0.3894, -0.3850,  ..., -0.0782, -0.6201,  0.2014],\n",
       "          [-0.0539, -0.0062, -0.1096,  ...,  0.2605,  0.6401, -0.2522],\n",
       "          [-0.2634, -0.1658, -0.1598,  ...,  0.0565,  0.6421,  0.6436],\n",
       "          ...,\n",
       "          [-0.1322, -0.3555, -0.0687,  ..., -0.1731, -0.0271,  0.0078],\n",
       "          [-0.2720, -0.0267, -0.4807,  ..., -0.3486, -0.2411, -0.3455],\n",
       "          [-0.2585,  0.0527, -0.5142,  ..., -0.6338,  0.0499,  0.2527]],\n",
       "         device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 13346, 575, 38942, 42893, 294, 5162, 3259, 11, 415, 8194, 572, 643, 337, 264, 12380, 26049, 281, 5300, 1179, 6846, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. currency has strengthened sharply in recent weeks, he sees no need for the Federal Reserve to raise interest rates to protect the dollar.', avg_logprob=-0.03825973763185389, no_speech_prob=1.1966396840437654e-12, temperature=0.0, compression_ratio=1.2881355932203389)],\n",
       " [DecodingResult(audio_features=tensor([[ 0.0569,  0.3462, -0.5776,  ..., -0.1310, -0.2703,  0.2328],\n",
       "          [ 0.0245,  0.1065, -0.3018,  ...,  0.2413,  0.5254, -0.3762],\n",
       "          [-0.1603,  0.0258, -0.1571,  ...,  0.1731,  0.4417,  0.4436],\n",
       "          ...,\n",
       "          [-0.1437, -0.5068, -0.2305,  ..., -0.1134,  0.0200, -0.0998],\n",
       "          [-0.2500, -0.2418, -0.7192,  ..., -0.1724, -0.3093, -0.4573],\n",
       "          [-0.2043,  0.2844, -0.6772,  ..., -0.4949, -0.0040,  0.3630]],\n",
       "         device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[50365, 4162, 264, 624, 13, 50, 13, 6969, 322, 6984, 11, 264, 3150, 486, 312, 3440, 797, 13, 50598, 50605, 634, 8194, 572, 643, 337, 264, 3825, 281, 5300, 264, 5397, 5632, 281, 2371, 264, 7241, 13, 50824], text='Since the U.S. Green on Friday, the board will be meeting again. He sees no need for the security to raise the credit cards to protect the dollar.', avg_logprob=-0.8490812839605869, no_speech_prob=7.625010865763837e-12, temperature=0.0, compression_ratio=1.2920353982300885)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt_mod.model.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_decensoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
